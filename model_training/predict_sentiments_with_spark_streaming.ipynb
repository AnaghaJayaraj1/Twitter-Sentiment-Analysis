{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter Sentiment Analysis with Pyspark\n",
    "\n",
    "# Predicting Sentiments with Spark Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Just created a SparkContext\n",
      "SparkContext Master: local[*]\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.streaming import StreamingContext\n",
    "from pyspark.sql import SQLContext, SparkSession\n",
    "import warnings\n",
    "\n",
    "SCC_CHECKPOINT_PATH = \"/Users/anujchaudhari/Desktop/256/project/samples/twitter_streaming/checkpoint\"\n",
    "STREAMING_SOCKET_IP = \"192.168.0.100\"\n",
    "STREAMING_SOCKET_PORT = 5555\n",
    "STREAMING_TIME_INTERVAL = 2\n",
    "\n",
    "try:\n",
    "    # create SparkContext on all CPUs available: in my case I have 4 CPUs on my laptop\n",
    "    \n",
    "    spark = SparkSession.builder.appName(\"twitter\").getOrCreate()\n",
    "    sc = spark.sparkContext\n",
    "    sqlContext = SQLContext(sc)\n",
    "\n",
    "    print(\"Just created a SparkContext\")\n",
    "    \n",
    "except ValueError:\n",
    "    warnings.warn(\"SparkContext already exists in this scope\")\n",
    "    \n",
    "    \n",
    "\n",
    "# Create Spark Streaming Context\n",
    "ssc = StreamingContext(sc, STREAMING_TIME_INTERVAL )\n",
    "\n",
    "ssc.checkpoint(SCC_CHECKPOINT_PATH)\n",
    "\n",
    "socket_stream = ssc.socketTextStream(STREAMING_SOCKET_IP, STREAMING_SOCKET_PORT)\n",
    "\n",
    "dStream = socket_stream.window(STREAMING_TIME_INTERVAL)\n",
    "\n",
    "print(\"SparkContext Master: \" + sc.master)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Previously Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.ml.pipeline.PipelineModel"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml import PipelineModel\n",
    "\n",
    "pipeline = PipelineModel.load(\"Model_Twitter_Sentiment\")\n",
    "\n",
    "type(pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tweet Cleaner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "tok = WordPunctTokenizer()\n",
    "\n",
    "pat1 = r'@[A-Za-z0-9_]+'\n",
    "pat2 = r'https?://[^ ]+'\n",
    "combined_pat = r'|'.join((pat1, pat2))\n",
    "www_pat = r'www.[^ ]+'\n",
    "negations_dic = {\"isn't\":\"is not\", \"aren't\":\"are not\", \"wasn't\":\"was not\", \"weren't\":\"were not\",\n",
    "                \"haven't\":\"have not\",\"hasn't\":\"has not\",\"hadn't\":\"had not\",\"won't\":\"will not\",\n",
    "                \"wouldn't\":\"would not\", \"don't\":\"do not\", \"doesn't\":\"does not\",\"didn't\":\"did not\",\n",
    "                \"can't\":\"can not\",\"couldn't\":\"could not\",\"shouldn't\":\"should not\",\"mightn't\":\"might not\",\n",
    "                \"mustn't\":\"must not\"}\n",
    "neg_pattern = re.compile(r'\\b(' + '|'.join(negations_dic.keys()) + r')\\b')\n",
    "\n",
    "def tweet_cleaner_updated(text):\n",
    "    soup = BeautifulSoup(text, 'lxml')\n",
    "    souped = soup.get_text()\n",
    "    try:\n",
    "        bom_removed = souped.decode(\"utf-8-sig\").replace(u\"\\ufffd\", \"?\")\n",
    "    except:\n",
    "        bom_removed = souped\n",
    "    stripped = re.sub(combined_pat, '', bom_removed)\n",
    "    stripped = re.sub(www_pat, '', stripped)\n",
    "    lower_case = stripped.lower()\n",
    "    neg_handled = neg_pattern.sub(lambda x: negations_dic[x.group()], lower_case)\n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", neg_handled)\n",
    "    # During the letters_only process two lines above, it has created unnecessay white spaces,\n",
    "    # I will tokenize and join together to remove unneccessary white spaces\n",
    "    words = [x for x  in tok.tokenize(letters_only) if len(x) > 1]\n",
    "    ret = (\" \".join(words)).strip()\n",
    "    return ret\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spark Streaming Tweet Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "\n",
    "def processTweets(rdd):\n",
    "    try:        \n",
    "        spark = SparkSession.builder.appName(\"twitter\").getOrCreate()\n",
    "        \n",
    "        tweet = rdd.collect()\n",
    "        if len(tweet) != 0:\n",
    "            tweet = list(tweet[0])\n",
    "        else:\n",
    "            tweet = []\n",
    "\n",
    "        rows = []\n",
    "        for i in range(len(tweet)):\n",
    "            cleaned_tweet = tweet_cleaner_updated(tweet[i])\n",
    "            rows.append(Row(_c0=i,text=cleaned_tweet,original=tweet[i],target=0))\n",
    "\n",
    "        if len(rows) == 0:\n",
    "            rows.append(Row(_c0=1,text=\"empty\",target=0))\n",
    "        \n",
    "        df = spark.createDataFrame(rows)\n",
    "        \n",
    "        from pyspark.ml import PipelineModel\n",
    "        \n",
    "        # Load Trained Model ( required because this code will be executed on worker nodes)\n",
    "        model = PipelineModel.load(\"Model_Twitter_Sentiment\")\n",
    "        \n",
    "        predicted_tweets = model.transform(df).collect()\n",
    "        \n",
    "        # send predicted result to redis queue for showing result on Dashboard\n",
    "        \n",
    "        import redis\n",
    "        import json\n",
    "        \n",
    "        config = {\n",
    "            'host' : 'localhost',\n",
    "            'port' : 6379,\n",
    "            'db' : 0\n",
    "        }\n",
    "        redis_object = redis.StrictRedis(**config)\n",
    "        channel = \"tweet_prediction\"\n",
    "        print(\"11111\")\n",
    "        for tweet in predicted_tweets:\n",
    "            print(\"22222\")\n",
    "            # Send Data to Redis Queue\n",
    "            message = {}\n",
    "            message[\"text\"] = tweet.original\n",
    "            message[\"sentiment\"] = tweet.prediction\n",
    "            message_body = json.dumps(message)\n",
    "            message = '{message_body}'.format(**locals()).encode('UTF-8')\n",
    "            print(\"33333\")\n",
    "            redis_object.publish(channel, message)\n",
    "        \n",
    "    except Exception as e: \n",
    "        print(e)\n",
    "    \n",
    "dStream = dStream.map(lambda x: x.lower());\n",
    "dStream = dStream.map(lambda x: x.replace(\" rt \" , \" \"))\n",
    "dStream = dStream.map(lambda x: x.replace(\"\\n\" , \" \"))\n",
    "dStream = dStream.reduce(lambda x,y : x + y)\n",
    "dStream = dStream.map(lambda x: x.split(\" $$$$$$ \"))\n",
    "\n",
    "dStream.foreachRDD(lambda rdd : processTweets(rdd))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssc.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
